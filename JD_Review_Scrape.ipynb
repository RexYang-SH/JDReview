{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commentSave(list_comment):\n",
    "    file = io.open('JD_Review_data.txt','w',encoding=\"utf-8\",newline = '')\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['ID','Review','Purchase date','Vote','Reply','Score','Review date','Model'])\n",
    "    for i in range(len(list_comment)):\n",
    "        writer.writerow(list_comment[i])\n",
    "    file.close()\n",
    "    print('Data Saved')\n",
    "\n",
    "def getCommentData(format_url,proc,i,maxPage):\n",
    "    sig_comment = []\n",
    "    global list_comment\n",
    "    cur_page = 0\n",
    "    while cur_page < maxPage:\n",
    "        cur_page += 1\n",
    "        # url = 'https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv%s&score=%s&sortType=5&page=%s&pageSize=10&isShadowSku=0&fold=1'%(proc,i,cur_page)\n",
    "        url = format_url.format(proc,i,cur_page) \n",
    "        try:\n",
    "            response = requests.get(url=url, headers=headers)\n",
    "            time.sleep(np.random.rand()*2)\n",
    "            jsonData = response.text\n",
    "            startLoc = jsonData.find('{')\n",
    "            #print(jsonData[::-1])\n",
    "            jsonData = jsonData[startLoc:-2]\n",
    "            jsonData = json.loads(jsonData)\n",
    "            pageLen = len(jsonData['comments'])\n",
    "            print(\"Page %s\"%cur_page)\n",
    "            for j in range(0,pageLen):\n",
    "                userId = jsonData['comments'][j]['id']\n",
    "                content = jsonData['comments'][j]['content']\n",
    "                boughtTime = jsonData['comments'][j]['referenceTime']\n",
    "                voteCount = jsonData['comments'][j]['usefulVoteCount']\n",
    "                replyCount = jsonData['comments'][j]['replyCount']\n",
    "                starStep = jsonData['comments'][j]['score']\n",
    "                creationTime = jsonData['comments'][j]['creationTime']\n",
    "                referenceName = jsonData['comments'][j]['referenceName']\n",
    "                sig_comment.append(userId)\n",
    "                sig_comment.append(content)\n",
    "                sig_comment.append(boughtTime)\n",
    "                sig_comment.append(voteCount)\n",
    "                sig_comment.append(replyCount)\n",
    "                sig_comment.append(starStep)\n",
    "                sig_comment.append(creationTime)\n",
    "                sig_comment.append(referenceName)\n",
    "                list_comment.append(sig_comment)\n",
    "                sig_comment = []\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "            cur_page -= 1\n",
    "            print('Network error, retry later')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    global list_comment\n",
    "    ua=UserAgent()\n",
    "    format_url = 'https://club.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98&{0}&score={1}&sortType=5&page={2}&pageSize=10&isShadowSku=0&fold=1'\n",
    "    headers = {\n",
    "    'Accept': '*/*',\n",
    "    \"User-Agent\":ua.random,\n",
    "    'Referer':\"https://item.jd.com/100000177760.html#comment\"\n",
    "    }\n",
    "    productid = ['productId=100018276690'] # Change to product id for scraping\n",
    "    list_comment = [[]]\n",
    "    sig_comment = []\n",
    "    for proc in productid:\n",
    "        i = 0\n",
    "        while i < 3: # change to score level: 1:lowest, 5:highest \n",
    "            i += 1\n",
    "            if(i == 6):\n",
    "                continue\n",
    "            url = format_url.format(proc,i,0)\n",
    "            print(url)\n",
    "            try:\n",
    "                response = requests.get(url=url, headers=headers)\n",
    "                jsonData = response.text\n",
    "                startLoc = jsonData.find('{')\n",
    "                jsonData = jsonData[startLoc:-2]\n",
    "                jsonData = json.loads(jsonData)\n",
    "                print(\"Max page %s\"%jsonData['maxPage'])\n",
    "                getCommentData(format_url,proc,i,jsonData['maxPage'])\n",
    "            except Exception as e:\n",
    "                i -= 1\n",
    "                print(\"the error is \",e)\n",
    "                print(\"wating---\")\n",
    "                time.sleep(5)\n",
    "                #commentSave(list_comment)\n",
    "    print(\"Scrape complete, saving data\")\n",
    "    commentSave(list_comment)"
   ]
  }
 ]
}
